# -*- coding: utf-8 -*-
"""CustomerChurns

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Vfw_g5gv8iLXKYryfH2_AXQU9AhcryGW

Installing scikeras
"""

!pip install scikeras

"""Importing the libraries"""

import pandas as pd
from google.colab import drive
from sklearn.feature_selection import RFECV
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from scikeras.wrappers import KerasClassifier
from keras.layers import Input, Dense
from keras.models import Sequential
from keras.optimizers import Adam
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import accuracy_score, roc_auc_score
import joblib
import matplotlib.pyplot as plt
import seaborn as sns
from keras.models import Model

"""Load the dataset"""

drive.mount('/content/drive')

from google.colab import drive

churn=pd.read_csv('/content/drive/My Drive/Colab Notebooks/CustomerChurn_dataset.csv')

"""Display basic information about the dataset"""

churn.head()

churn.info(verbose=True, null_counts=True)

"""Separating the X and the Y"""

X = churn.drop('Churn', axis=1)
y = churn['Churn']

"""Encoding the X"""

# Create a LabelEncoder
label_encoder = LabelEncoder()
for column in X.select_dtypes(include=['object']).columns:
    X[column] = label_encoder.fit_transform(X[column])

"""Scaling the numerical features"""

# Scale the numerical features
scaler = StandardScaler()
numerical_columns = X.select_dtypes(include=['int64', 'float64']).columns
X[numerical_columns] = scaler.fit_transform(X[numerical_columns])

"""Split the dataset into training and testing sets

"""

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)

# Initialize RFECV with the random forest classifier
rfecv = RFECV(estimator=rf_classifier, step=1, cv=5, scoring='accuracy')

# Fit RFECV on the training data
rfecv.fit(X_train, y_train)

# Display the optimal number of features
print("Optimal number of features : {}".format(rfecv.n_features_))

# Get the selected features
selected_features = X_train.columns[rfecv.support_]

# Display the selected features
print("Selected Features: ", selected_features)

# Fit the random forest classifier on the selected features
rf_classifier.fit(X_train[selected_features], y_train)

# Display feature importances
feature_importances = pd.DataFrame({'Feature': selected_features, 'Importance': rf_classifier.feature_importances_})
feature_importances = feature_importances.sort_values(by='Importance', ascending=False)
print("\nFeature Importances:")
print(feature_importances)

"""Initializing and fitting into the Random Forest classifier and finding the top 10 features

"""

# Fit RFECV on the training data
rfecv.fit(X_train, y_train)

# Display the optimal number of features
print("Optimal number of features: {}".format(rfecv.n_features_))

# Get the selected features
selected_features = X_train.columns[rfecv.support_]

# Display the selected features
print("Selected Features: ", selected_features)

# Get the top 10 features based on feature importances
top_10_features = feature_importances.head(10)['Feature']

# Display the top 10 features
print("Top 10 Features:")
print(top_10_features)

# Assuming top_10_features is the correct set of features
selected_features = top_10_features

"""The EDA, visualization, and customer profiles"""

churn.describe()

churn.info()

plt.figure(figsize=(8, 5))
sns.countplot(x='Churn', data=churn)
plt.title('Distribution of Churn')
plt.show()

# Explore relationships between categorical features and churn
categorical_columns = churn[top_10_features].select_dtypes(include=['object']).columns

for column in categorical_columns:
    plt.figure(figsize=(10, 5))
    sns.countplot(x=column, hue='Churn', data=churn)
    plt.title(f'{column} vs Churn')
    plt.xticks(rotation=45)
    plt.show()

# Explore relationships between numerical features and churn
numerical_columns = churn[top_10_features].select_dtypes(include=['int64', 'float64']).columns

for column in numerical_columns:
    plt.figure(figsize=(10, 5))
    sns.kdeplot(x=column, hue='Churn', data=churn, fill=True)
    plt.title(f'{column} Distribution by Churn')
    plt.show()

"""Creating the customer profile"""

# Define the customer profile to investigate
profile_to_investigate = {
    'SeniorCitizen': 1,  # Senior citizen
    'gender': 'Male',    # Gender: Male
    'Partner': 'Yes',    # Has a partner
    'Dependents': 'Yes'  # Has dependents
}

# Create a mask for the specified customer profile
mask = (churn['SeniorCitizen'] == profile_to_investigate['SeniorCitizen']) & \
       (churn['gender'] == profile_to_investigate['gender']) & \
       (churn['Partner'] == profile_to_investigate['Partner']) & \
       (churn['Dependents'] == profile_to_investigate['Dependents'])

# Subset the dataset based on the mask
profile_df = churn[mask]

# Visualize the distribution of churn for the specified profile
plt.figure(figsize=(8, 5))
sns.countplot(x='Churn', data=profile_df)
plt.title('Distribution of Churn for the Specified Profile')
plt.show()

# Explore relationships between other features and churn for the specified profile
for column in numerical_columns:
    plt.figure(figsize=(10, 5))
    sns.kdeplot(x=column, hue='Churn', data=profile_df, fill=True)
    plt.title(f'{column} Distribution by Churn for the Specified Profile')
    plt.show()

label_encoder_y = LabelEncoder()
y_train = label_encoder_y.fit_transform(y_train)
y_test = label_encoder_y.transform(y_test)

"""Create a simple MLP model using Keras and using gridsearch


"""

from scikeras.wrappers import KerasClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import accuracy_score, roc_auc_score
from keras.models import Sequential
from keras.layers import Input, Dense
from keras.optimizers import Adam
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
import pandas as pd
import joblib

def create_mpl_model(input_shape):
    input_layer = Input(shape=(input_shape,))
    hidden_layer_1 = Dense(32, activation='relu')(input_layer)
    hidden_layer_2 = Dense(24, activation='relu')(hidden_layer_1)
    hidden_layer_3 = Dense(12, activation='relu')(hidden_layer_2)
    output_layer = Dense(1, activation='sigmoid')(hidden_layer_3)

    model = Model(inputs=input_layer, outputs=output_layer)
    model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])

    return model

# Assuming X_train[selected_features].shape[1] is the correct input shape
input_shape = X_train[selected_features].shape[1]
model = create_mpl_model(input_shape)

# Fit the model
model.fit(X_train[selected_features], y_train, epochs=30, batch_size=32, validation_data=(X_test[selected_features], y_test))

# Use KerasClassifier for GridSearchCV
keras_classifier = KerasClassifier(build_fn=lambda: model, verbose=0)

# Define grid search parameters
param_grid = {
    'epochs': [20, 30, 40],
    'batch_size': [32, 64, 128],
}

# Create GridSearchCV object
grid_search = GridSearchCV(keras_classifier, param_grid, cv=5, scoring='accuracy')
# Fit GridSearchCV on the training data
grid_search.fit(X_train[selected_features], y_train)

"""Using the best keras model and tevaluating the model for the best"""

best_keras_model = grid_search.best_estimator_

y_pred = best_keras_model.predict(X_test[selected_features])
y_pred_proba = best_keras_model.predict_proba(X_test[selected_features])[:, 1]

"""Calculating the accuracy and the auc score"""

# Calculate accuracy and AUC score
accuracy = accuracy_score(y_test, y_pred)
auc_score = roc_auc_score(y_test, y_pred_proba)

print("Accuracy:", accuracy)
print("AUC Score:", auc_score)

# Train and test the optimized model again
best_keras_model.fit(X_train[top_10_features], y_train)
y_pred_optimized = best_keras_model.predict(X_test[selected_features])
accuracy_optimized = accuracy_score(y_test, y_pred_optimized)

print("Accuracy on optimized model:", accuracy_optimized)

"""Retraining the model based on the best hyper parameters"""

# Create GridSearchCV object
grid_search = GridSearchCV(keras_classifier, param_grid, cv=5, scoring='accuracy')
# Fit GridSearchCV on the training data
grid_search.fit(X_train[selected_features], y_train)

# Access the best hyperparameters from the grid_search object
best_params = grid_search.best_params_

# Retrain the model with the best hyperparameters
best_epochs = best_params['epochs']
best_batch_size = best_params['batch_size']

# Create the model with the best hyperparameters
best_model = create_mpl_model(input_shape)  # No need to specify learning_rate here

# Retrain the model on the entire training set
best_model.fit(X_train[selected_features], y_train, epochs=best_epochs, batch_size=best_batch_size)

# Evaluate the retrained model on the test set
y_pred_retrained = best_model.predict(X_test[selected_features])
y_pred_proba_retrained = y_pred_retrained  # Since there's no predict_proba, use the raw output as probabilities

# Calculate accuracy and AUC score for the retrained model
accuracy_retrained = accuracy_score(y_test, y_pred_retrained.round())  # Adjusted to use rounded predictions
auc_score_retrained = roc_auc_score(y_test, y_pred_proba_retrained)

print("Accuracy on Retrained Model:", accuracy_retrained)
print("AUC Score on Retrained Model:", auc_score_retrained)

"""Saving the model to a pickle file"""

import joblib

# Save the model using joblib
joblib.dump(best_model, '/content/drive/My Drive/Colab Notebooks/Churn_Mod.pkl')

joblib.dump(label_encoder, ' /content/drive/My Drive/Colab Notebooks/label_encoded.pkl')

history = model.fit(X_train[selected_features], y_train, epochs=30, batch_size=32, validation_data=(X_test[selected_features], y_test))

# Print accuracy and loss over epochs
print("Training Accuracy:", history.history['accuracy'])
print("Training Loss:", history.history['loss'])

# Print validation accuracy and loss over epochs
print("Validation Accuracy:", history.history['val_accuracy'])
print("Validation Loss:", history.history['val_loss'])